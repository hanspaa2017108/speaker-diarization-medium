{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d89c820b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: speechbrain==1.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: hyperpyyaml in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from speechbrain==1.0) (1.2.2)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from speechbrain==1.0) (1.5.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from speechbrain==1.0) (2.3.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from speechbrain==1.0) (25.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from speechbrain==1.0) (1.16.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from speechbrain==1.0) (0.2.1)\n",
      "Requirement already satisfied: torch>=1.9 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from speechbrain==1.0) (2.8.0)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from speechbrain==1.0) (2.8.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from speechbrain==1.0) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from speechbrain==1.0) (0.35.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from torch>=1.9->speechbrain==1.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from torch>=1.9->speechbrain==1.0) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from torch>=1.9->speechbrain==1.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from torch>=1.9->speechbrain==1.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from torch>=1.9->speechbrain==1.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from torch>=1.9->speechbrain==1.0) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.9->speechbrain==1.0) (1.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from huggingface-hub->speechbrain==1.0) (6.0.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from huggingface-hub->speechbrain==1.0) (2.32.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from huggingface-hub->speechbrain==1.0) (1.1.10)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from hyperpyyaml->speechbrain==1.0) (0.18.15)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain==1.0) (0.2.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from jinja2->torch>=1.9->speechbrain==1.0) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from requests->huggingface-hub->speechbrain==1.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from requests->huggingface-hub->speechbrain==1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from requests->huggingface-hub->speechbrain==1.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from requests->huggingface-hub->speechbrain==1.0) (2025.8.3)\n",
      "Requirement already satisfied: faster_whisper in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: ctranslate2<5,>=4.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from faster_whisper) (4.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from faster_whisper) (0.35.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.13 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from faster_whisper) (0.22.1)\n",
      "Requirement already satisfied: onnxruntime<2,>=1.14 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from faster_whisper) (1.23.0)\n",
      "Requirement already satisfied: av>=11 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from faster_whisper) (15.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from faster_whisper) (4.67.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from ctranslate2<5,>=4.0->faster_whisper) (78.1.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from ctranslate2<5,>=4.0->faster_whisper) (2.3.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from ctranslate2<5,>=4.0->faster_whisper) (6.0.3)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster_whisper) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster_whisper) (25.9.23)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster_whisper) (25.0)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster_whisper) (5.29.5)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster_whisper) (1.14.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster_whisper) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster_whisper) (2025.9.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster_whisper) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster_whisper) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster_whisper) (1.1.10)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from coloredlogs->onnxruntime<2,>=1.14->faster_whisper) (10.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13->faster_whisper) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13->faster_whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13->faster_whisper) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13->faster_whisper) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from sympy->onnxruntime<2,>=1.14->faster_whisper) (1.3.0)\n",
      "Requirement already satisfied: pyannote.audio in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (4.0.0)\n",
      "Requirement already satisfied: asteroid-filterbanks>=0.4.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (0.4.0)\n",
      "Requirement already satisfied: einops>=0.8.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (0.35.3)\n",
      "Requirement already satisfied: lightning>=2.4 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (2.5.5)\n",
      "Requirement already satisfied: matplotlib>=3.10.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (3.10.6)\n",
      "Requirement already satisfied: opentelemetry-api==1.34.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (1.34.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp==1.34.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (1.34.0)\n",
      "Requirement already satisfied: opentelemetry-sdk==1.34.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (1.34.0)\n",
      "Requirement already satisfied: pyannote-core>=6.0.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (6.0.1)\n",
      "Requirement already satisfied: pyannote-database>=6.0.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (6.1.0)\n",
      "Requirement already satisfied: pyannote-metrics>=4.0.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (4.0.0)\n",
      "Requirement already satisfied: pyannote-pipeline>=4.0.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (4.0.0)\n",
      "Requirement already satisfied: pyannoteai-sdk>=0.2.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (0.2.1)\n",
      "Requirement already satisfied: pytorch-metric-learning>=2.8.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (2.9.0)\n",
      "Requirement already satisfied: rich>=13.9.4 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (14.1.0)\n",
      "Requirement already satisfied: safetensors>=0.5.2 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (0.6.2)\n",
      "Requirement already satisfied: soundfile>=0.13.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (0.13.1)\n",
      "Requirement already satisfied: torch-audiomentations>=0.12.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (0.12.0)\n",
      "Requirement already satisfied: torch>=2.8.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (2.8.0)\n",
      "Requirement already satisfied: torchaudio>=2.8.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (2.8.0)\n",
      "Requirement already satisfied: torchcodec>=0.6.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (0.7.0)\n",
      "Requirement already satisfied: torchmetrics>=1.6.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote.audio) (1.8.2)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from opentelemetry-api==1.34.0->pyannote.audio) (8.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from opentelemetry-api==1.34.0->pyannote.audio) (4.15.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.34.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from opentelemetry-exporter-otlp==1.34.0->pyannote.audio) (1.34.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.34.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from opentelemetry-exporter-otlp==1.34.0->pyannote.audio) (1.34.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.34.0->opentelemetry-exporter-otlp==1.34.0->pyannote.audio) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.34.0->opentelemetry-exporter-otlp==1.34.0->pyannote.audio) (1.75.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.34.0->opentelemetry-exporter-otlp==1.34.0->pyannote.audio) (1.34.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.34.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.34.0->opentelemetry-exporter-otlp==1.34.0->pyannote.audio) (1.34.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from opentelemetry-sdk==1.34.0->pyannote.audio) (0.55b0)\n",
      "Requirement already satisfied: requests~=2.7 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http==1.34.0->opentelemetry-exporter-otlp==1.34.0->pyannote.audio) (2.32.5)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from opentelemetry-proto==1.34.0->opentelemetry-exporter-otlp-proto-grpc==1.34.0->opentelemetry-exporter-otlp==1.34.0->pyannote.audio) (5.29.5)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api==1.34.0->pyannote.audio) (3.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.34.0->opentelemetry-exporter-otlp==1.34.0->pyannote.audio) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.34.0->opentelemetry-exporter-otlp==1.34.0->pyannote.audio) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.34.0->opentelemetry-exporter-otlp==1.34.0->pyannote.audio) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.34.0->opentelemetry-exporter-otlp==1.34.0->pyannote.audio) (2025.8.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from asteroid-filterbanks>=0.4.0->pyannote.audio) (2.3.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (6.0.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (1.1.10)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from lightning>=2.4->pyannote.audio) (0.15.2)\n",
      "Requirement already satisfied: pytorch-lightning in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from lightning>=2.4->pyannote.audio) (2.5.5)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (3.12.15)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.4->pyannote.audio) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from torch>=2.8.0->pyannote.audio) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from torch>=2.8.0->pyannote.audio) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from torch>=2.8.0->pyannote.audio) (3.1.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (1.20.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from matplotlib>=3.10.0->pyannote.audio) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from matplotlib>=3.10.0->pyannote.audio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from matplotlib>=3.10.0->pyannote.audio) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from matplotlib>=3.10.0->pyannote.audio) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from matplotlib>=3.10.0->pyannote.audio) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from matplotlib>=3.10.0->pyannote.audio) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from matplotlib>=3.10.0->pyannote.audio) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=2.2.3 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote-core>=6.0.1->pyannote.audio) (2.3.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote-core>=6.0.1->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pandas>=2.2.3->pyannote-core>=6.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pandas>=2.2.3->pyannote-core>=6.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: scikit-learn>=1.6.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote-metrics>=4.0.0->pyannote.audio) (1.7.2)\n",
      "Requirement already satisfied: scipy>=1.15.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote-metrics>=4.0.0->pyannote.audio) (1.16.2)\n",
      "Requirement already satisfied: optuna>=4.2.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pyannote-pipeline>=4.0.0->pyannote.audio) (4.5.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from optuna>=4.2.0->pyannote-pipeline>=4.0.0->pyannote.audio) (1.16.5)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from optuna>=4.2.0->pyannote-pipeline>=4.0.0->pyannote.audio) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from optuna>=4.2.0->pyannote-pipeline>=4.0.0->pyannote.audio) (2.0.43)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from alembic>=1.5.0->optuna>=4.2.0->pyannote-pipeline>=4.0.0->pyannote.audio) (1.3.10)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.10.0->pyannote.audio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from rich>=13.9.4->pyannote.audio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from rich>=13.9.4->pyannote.audio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->pyannote.audio) (0.1.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from scikit-learn>=1.6.1->pyannote-metrics>=4.0.0->pyannote.audio) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from scikit-learn>=1.6.1->pyannote-metrics>=4.0.0->pyannote.audio) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from soundfile>=0.13.1->pyannote.audio) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.13.1->pyannote.audio) (2.23)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.8.0->pyannote.audio) (1.3.0)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from torch-audiomentations>=0.12.0->pyannote.audio) (0.2.7)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from torch-audiomentations>=0.12.0->pyannote.audio) (1.2.5)\n",
      "Requirement already satisfied: primePy>=1.3 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.12.0->pyannote.audio) (1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from jinja2->torch>=2.8.0->pyannote.audio) (3.0.3)\n",
      "Requirement already satisfied: whisper in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (1.1.10)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from whisper) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install speechbrain==1.0\n",
    "!pip install faster_whisper\n",
    "!pip install pyannote.audio\n",
    "!pip install whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aee07fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import traceback\n",
    "from faster_whisper import WhisperModel\n",
    "import torch\n",
    "import whisper\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding\n",
    "from pyannote.audio import Audio\n",
    "from pyannote.core import Segment\n",
    "import speechbrain\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d17d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = '/Users/hanama/Desktop/AEOS_WORK/labs/Speaker-Diarization/inputs/audios/audio-2.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15699f4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "'speechbrain' must be installed to use 'speechbrain/spkrec-ecapa-voxceleb' embeddings. Visit https://speechbrain.github.io for installation instructions.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Define whisper models and embedding model\u001b[39;00m\n\u001b[32m      2\u001b[39m whisper_models = [\u001b[33m\"\u001b[39m\u001b[33mtiny\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbase\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msmall\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmedium\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlarge-v1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlarge-v2\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m embedding_model = \u001b[43mPretrainedSpeakerEmbedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspeechbrain/spkrec-ecapa-voxceleb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Helper function to convert seconds to a timestamp\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_time\u001b[39m(secs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages/pyannote/audio/pipelines/speaker_verification.py:762\u001b[39m, in \u001b[36mPretrainedSpeakerEmbedding\u001b[39m\u001b[34m(embedding, device, token, cache_dir)\u001b[39m\n\u001b[32m    757\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PyannoteAudioPretrainedSpeakerEmbedding(\n\u001b[32m    758\u001b[39m         embedding, device=device, token=token, cache_dir=cache_dir\n\u001b[32m    759\u001b[39m     )\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embedding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mspeechbrain\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m embedding:\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSpeechBrainPretrainedSpeakerEmbedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    763\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\n\u001b[32m    764\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embedding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnvidia\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m embedding:\n\u001b[32m    767\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m NeMoPretrainedSpeakerEmbedding(embedding, device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages/pyannote/audio/pipelines/speaker_verification.py:239\u001b[39m, in \u001b[36mSpeechBrainPretrainedSpeakerEmbedding.__init__\u001b[39m\u001b[34m(self, embedding, device, token, cache_dir)\u001b[39m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    232\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    233\u001b[39m     embedding: Text = \u001b[33m\"\u001b[39m\u001b[33mspeechbrain/spkrec-ecapa-voxceleb\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    236\u001b[39m     cache_dir: Union[Path, Text, \u001b[38;5;28;01mNone\u001b[39;00m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    237\u001b[39m ):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SPEECHBRAIN_IS_AVAILABLE:\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    240\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mspeechbrain\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be installed to use \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m embeddings. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    241\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mVisit https://speechbrain.github.io for installation instructions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    242\u001b[39m         )\n\u001b[32m    244\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m@\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m embedding:\n",
      "\u001b[31mImportError\u001b[39m: 'speechbrain' must be installed to use 'speechbrain/spkrec-ecapa-voxceleb' embeddings. Visit https://speechbrain.github.io for installation instructions."
     ]
    }
   ],
   "source": [
    "# Define whisper models and embedding model\n",
    "whisper_models = [\"tiny\", \"base\", \"small\", \"medium\", \"large-v1\", \"large-v2\"]\n",
    "embedding_model = PretrainedSpeakerEmbedding(\n",
    "    \"speechbrain/spkrec-ecapa-voxceleb\",\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "# Helper function to convert seconds to a timestamp\n",
    "def convert_time(secs):\n",
    "    return datetime.timedelta(seconds=round(secs))\n",
    "\n",
    "# Main function to perform speech-to-text and diarization\n",
    "def speech_to_text(audio_file, whisper_model):\n",
    "    model = WhisperModel(whisper_model, compute_type=\"int8\")\n",
    "    \n",
    "    # Load audio and get duration\n",
    "    audio_data, sample_rate = librosa.load(audio_file, mono=True, sr=16000)\n",
    "    duration = len(audio_data) / sample_rate\n",
    "    \n",
    "    # Transcribe audio to get segments\n",
    "    options = dict(language=\"en\", beam_size=5, best_of=5)\n",
    "    transcribe_options = dict(task=\"transcribe\", **options)\n",
    "    segments_raw, info = model.transcribe(audio_file, **transcribe_options)\n",
    "    \n",
    "    segments = [{'start': s.start, 'end': s.end} for s in segments_raw]\n",
    "    \n",
    "    # Function to extract embedding for a single segment\n",
    "    def segment_embedding(segment):\n",
    "        audio = Audio()\n",
    "        start = segment[\"start\"]\n",
    "        end = min(duration, segment[\"end\"])\n",
    "        clip = Segment(start, end)\n",
    "        waveform, _ = audio.crop(audio_file, clip)\n",
    "        return embedding_model(waveform[None])\n",
    "\n",
    "    # Extract embeddings for all segments\n",
    "    embeddings = np.zeros(shape=(len(segments), 192))\n",
    "    for i, segment in enumerate(segments):\n",
    "        embeddings[i] = segment_embedding(segment)\n",
    "    embeddings = np.nan_to_num(embeddings)\n",
    "\n",
    "    # Perform clustering\n",
    "    clustering = AgglomerativeClustering(n_clusters=2).fit(embeddings)\n",
    "    labels = clustering.labels_\n",
    "    for i in range(len(segments)):\n",
    "        segments[i][\"speaker\"] = 'SPEAKER ' + str(labels[i] + 1)\n",
    "        \n",
    "    # Format results for output\n",
    "    objects = {'Start': [], 'End': [], 'Speaker': []}\n",
    "    for i, segment in enumerate(segments):\n",
    "        if i == 0 or segments[i-1][\"speaker\"] != segment[\"speaker\"]:\n",
    "            objects['Start'].append(str(convert_time(segment[\"start\"])))\n",
    "            if i > 0:\n",
    "                objects['End'].append(str(convert_time(segments[i-1][\"end\"])))\n",
    "            objects['Speaker'].append(segment[\"speaker\"])\n",
    "    objects['End'].append(str(convert_time(segments[-1][\"end\"])))\n",
    "    \n",
    "    df_results = pd.DataFrame(objects)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37731588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (11.3.0)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from moviepy) (5.2.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from moviepy) (2.37.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from moviepy) (2.3.3)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from moviepy) (0.1.12)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from moviepy) (1.1.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from proglog<=1.0.0->moviepy) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/speaker-diarization/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy pandas pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a12caae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.editor'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmoviepy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meditor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip, ImageClip, CompositeVideoClip\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, ImageDraw, ImageFont\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load the diarization results and the video\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'moviepy.editor'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Load the diarization results and the video\n",
    "df_results = transcription_results\n",
    "video_path = '/Users/hanama/Desktop/AEOS_WORK/labs/Speaker-Diarization/inputs/videos/video-2.mp4'\n",
    "video = VideoFileClip(video_path)\n",
    "\n",
    "# Function to create an image with text\n",
    "def create_text_image(text, font_size=70, img_size=(640, 80), bg_color=(0,0,0), text_color=(255,255,255)):\n",
    "    img = Image.new('RGB', img_size, color=bg_color)\n",
    "    d = ImageDraw.Draw(img)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "    text_width, text_height = d.textsize(text, font=font)\n",
    "    position = ((img_size[0] - text_width) / 2, (img_size[1] - text_height) / 2)\n",
    "    d.text(position, text, fill=text_color, font=font)\n",
    "    return img\n",
    "\n",
    "# Create and overlay text clips for each speaker segment\n",
    "clips = [video]\n",
    "for _, row in df_results.iterrows():\n",
    "    start_time = pd.to_datetime(row['Start']).time()\n",
    "    end_time = pd.to_datetime(row['End']).time()\n",
    "    start_seconds = start_time.hour * 3600 + start_time.minute * 60 + start_time.second\n",
    "    end_seconds = end_time.hour * 3600 + end_time.minute * 60 + end_time.second\n",
    "    \n",
    "    text_img = create_text_image(row['Speaker'])\n",
    "    text_img_path = '/content/temp_text_img.png'\n",
    "    text_img.save(text_img_path)\n",
    "    \n",
    "    txt_clip = (ImageClip(text_img_path)\n",
    "                .set_position(('center', 'bottom'))\n",
    "                .set_start(start_seconds)\n",
    "                .set_duration(end_seconds - start_seconds))\n",
    "    clips.append(txt_clip)\n",
    "\n",
    "# Combine clips and save the final video\n",
    "final_video = CompositeVideoClip(clips)\n",
    "final_video_path = '/Users/hanama/Desktop/AEOS_WORK/labs/Speaker-Diarization/inputs/videoplayback_label.mp4'\n",
    "final_video.write_videofile(final_video_path, codec='libx264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5116d2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speaker-diarization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
